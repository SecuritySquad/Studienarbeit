\chapter{Umsetzung}

In diesem Kapitel wird nun aufbauend auf dem im vorherigen Kapitel beschriebenen Konzept die Umsetzung von webifier beschrieben. Zunächst folgt nun die Erläuterung der Gesamtumsetzung, gefolgt von der Umsetzung der Teilanwendungen. Abschließend wird die Implementierung der einzelnen Tests vorgestellt.

\section{Gesamtanwendung}

\todo{Daniel}

\subsection{webifier Tests}
In diesem Abschnitt wird der allgemeine Aufbau, welcher für alle Tests von webifier gilt, erläutert.

Um die Tests vom Gesamtsystem abzukapseln wird auf Docker gesetzt. Hierbei wird für jeden Test ein eigenes Image geschrieben. Die Tests werden vom Tester dann gestartet. So wird jeder Test in einem eigenen Container ausgeführt. So ist sichergestellt, dass die Tests unabhängig von äußeren Faktoren sind und sich gegenseitig oder das Gesamtsystem nicht beeinflussen.

Die Technologien der einzelnen Tests sind abhängig vom jeweiligen Test und werden deshalb in den jeweiligen Kapiteln erläutert. Die Ergebnisübermittelung der Tests an den Tester wird mittels \ac{JSON}-Strings realisiert. Wie in Beispiel (...) zu sehen besteht das \ac{JSON} aus dem Testergebnis und einer ResultInfo. Die ResultInfo varriert von Test zu Test. Hier können für jeden Test weitergehende Informationen übermittelt werden. Für den Test auf Portscanning wird beispielsweise eine Liste von verdächtigen Portanfragen übermittelt.

\begin{scriptsize}
\lstset{
    style=eclipsejavascript,
    caption={Result JSON},
    label={lst:resultjson}
}
\begin{lstlisting}
  {
  	"result": "clean" | "suspicious" | "malicious" | "undefined",
  	"info": {
  		...
  	}
  }
\end{lstlisting}
\end{scriptsize}

\begin{itemize}
  \item Beschreiben der Startparameter URL und ID
\end{itemize}

\subsection{webifier Tester}

Der webifier Tester wurde als Anwendung für das \ac{CLI} in Java implementiert. Der Tester kann mit Hilfer verschiedener Parameter in seinem Verhalten gesteuert werden. Die Option \lstinline[style=eclipse]{-h} gibt beispielsweise die in Listing \ref{lst:tester-help} dargestellte Hilfe aus.

\begin{scriptsize}
\lstset{
    style=eclipse,
    caption={Hilfe webifier Tester},
    label={lst:tester-help}
}
\begin{lstlisting}
usage: java -jar webifier-tester.jar
 -h,--help              Print this help screen.
 -i,--id <ID>           Set the id for this test
 -o,--output <FORMAT>   Set the format of the output. Valid formats are
                        JSON and XML.
 -u,--url <URL>         The url that should be tested.
\end{lstlisting}
\end{scriptsize}

Die einzig erforderliche Option ist \lstinline[style=eclipse]{-u} mit welcher die zu überprüfende Url angegeben wird. Mit der Option \lstinline[style=eclipse]{-i} kann dem Test eine Id gegeben werden. Wird keine Id angegeben generiert der Tester eigenständig eine Id für den gestarteten Test. Mit der Option \lstinline[style=eclipse]{-o} kann ein Ausgebaformat spezifiziert werden. Dies ist vorallem für die automatisierte Testausführung, beispielsweise mit webifier Plattform relevant. Mögliche Ausgabeformate sind \ac{JSON} und \ac{XML}. Ist ein Ausgabeformat angegeben werden alle Events (Start und Ende der Tests) im jeweiligen Format ausgegeben. Wird kein Format spezifiziert so werden die Ergebnisse wie in Listing \ref{lst:tester-result} dargestellt ausgegeben.

\begin{scriptsize}
\lstset{
    style=eclipse,
    caption={Standardausgabe webifier Tester},
    label={lst:tester-result}
}
\begin{lstlisting}
$ java -jar webifier-tester.jar -u securitysquad.de
Resolver started for url securitysquad.de
Resolver finished! Result:
The resolved url is 'https://www.securitysquad.de/' and it is reachable.
Start Tester for url https://www.securitysquad.de/
Test 'VirusScan' started!
Test 'PhishingDetector' started!
Test 'CertificateChecker' started!
Test 'Screenshot' started!
Test 'IpScan' started!
Test 'GoogleSafeBrowsing' started!
Test 'LinkChecker' started!
Test 'PortScan' started!
Test 'HeaderInspection' started!
Test 'CertificateChecker' finished! Result:
The given url is clean!
Test 'HeaderInspection' finished! Result:
The given url is clean!
Test 'Screenshot' finished! Result:
The given url is clean!
Test 'GoogleSafeBrowsing' finished! Result:
The given url is clean!
Test 'LinkChecker' finished! Result:
The test result is undefined. Maybe the test returned an error!
Test 'IpScan' finished! Result:
The given url is clean!
Test 'PortScan' finished! Result:
The given url is clean!
Test 'PhishingDetector' finished! Result:
The given url is clean!
Test 'VirusScan' finished! Result:
The given url is clean!
Tester finished for url https://www.securitysquad.de/
The url is clean!
\end{lstlisting}
\end{scriptsize}

Wie im Konzept bereits erwähnt verwaltet der Tester alle auszuführenden Tests. Um die Tests dynamisch anpassen zu können werden alle notwendigen Parameter in einer Konfigurationsdatei gespeichert. Listing \ref{lst:tester-config} zeigt einen Ausschnitt dieser Datei.

Jeder Test hat einen eindeutigen Namen, seine Gewichtung, ein Befehl zum Ausführen und zum Beenden des Tests, sowie dafür vorgesehene Timeoutzeiten in Sekunden. Außerdem hat jeder Test einen Parameter, welcher die Java-Klasse für das Testergebnis angibt und einen Parameter mit dem der Test aktiviert oder deaktiviert werden kann. Bei der Ausführung und beim Beenden der Tests werden die Platzhalter \lstinline[style=eclipse]{#ID} und \lstinline[style=eclipse]{#URL} durch die generierten, bzw. vom Nutzer angegebenen Daten ersetzt.

\begin{scriptsize}
\lstset{
    style=eclipsejavascript,
    caption=[Ausschnitt Konfigurationsdatei webifier Tester]{Ausschnitt Konfigurationsdatei webifier Tester\protect\footnotemark},
    label={lst:tester-config}
}
\begin{lstlisting}
{
  "resolver": {
    "name": "resolver",
    "startup": "docker run --rm --name #ID -e URL=#URL -e ID=#ID webifier-resolver",
    "startup_timeout_seconds": 60,
    "shutdown": "docker stop #ID",
    "shutdown_timeout_seconds": 30
  },
  "tests": [
    {
      "name": "VirusScan",
      "startup": "docker run --rm --name #ID -e URL=#URL -e ID=#ID webifier-test-virusscan",
      "startup_timeout_seconds": 600,
      "shutdown": "docker stop #ID",
      "shutdown_timeout_seconds": 30,
      "result_class": "de.securitysquad.webifier.output.result.virusscan.TestVirusScanResultInfo",
      "weight": 5,
      "enabled": true
    }
    ...
  ],
  "preferences": {
    "push_result_data": true
  }
}
\end{lstlisting}
\end{scriptsize}
\footnotetext{Der vollständige Inhalt der Konfigurationsdatei befindet sich in Anhang \appref{b}.}

Am Ende der Datei lässt sich noch die Einstellung festlegen, ob das Endergebnis an webifier Data gesendet werden soll oder nicht. Am Anfang der Datei lässt sich der so genannte \textit{Resolver} konfigurieren. Dieser Prüft vor allen anderen Tests ob die angeforderte Seite überhaupt erreichbar ist und löst wenn nötig Weiterleitungen der Url auf und gibt das Ergebnis an den Tester zurück.

Ist die angegebene Url erreichbar wird die vom \textit{Resolver} aufgelöste Url verwendet und alle anderen Tests damit gestartet. Nun wartet der Tester bis alle Ergebnisse der Tests verfügbar sind oder die Angegebenen Timeouts erreicht sind. Im Falle eines Timeouts erhält der Test das Ergebnis \textit{UNDEFINED}. Abschließend wird das Gesamtergebnis für die angegebene Url wie bereits in Abschnitt \ref{sec:konzept-tester} beschrieben berechnet. Listing \ref{lst:tester-tesult-calculation} zeigt einen Ausschnitt der Implementierung der Ergebnisberechnung.

\begin{scriptsize}
\lstset{
    style=eclipsejava,
    caption=[Ausschnitt Ergebnisberechnung webifier Tester]{Ausschnitt Ergebnisberechnung webifier Tester\protect\footnotemark},
    label={lst:tester-config}
}
\begin{lstlisting}
private WebifierOverallTestResult calculateOverallResult() {
    ...
    if (undefinedPercentage > #MAX_UNDEFINED_TEST_PERCENTAGE#) {
        return new WebifierOverallTestResult(WebifierResultType.##UNDEFINED##);
    }
    double result = 0;
    for (WebifierTest<TestResult> test : tests) {
        double testWeight = (double) test.getData().getWeight() / (double) weightSum;
        result += getTestResultValue(test.getResult().getResultType(), testWeight) * testWeight;
    }
    if (result >= maliciousMin) {
        return new WebifierOverallTestResult(WebifierResultType.##MALICIOUS##, result);
    }
    if (result >= suspiciousMin) {
        return new WebifierOverallTestResult(WebifierResultType.##SUSPICIOUS##, result);
    }
    return new WebifierOverallTestResult(WebifierResultType.##CLEAN##, result);
}
\end{lstlisting}
\end{scriptsize}
\footnotetext{Der vollständige Inhalt der Ergebnisberechnung befindet sich in Anhang \appref{c}.}

Nachdem alle Tests ausgeführt wurden und das Gesamtresultat zusammengefasst wurde wird dieses über die von webifier Data bereitgestellte Schnittstelle dort gespeichert. Die Kommunikation mit webifier Data läuft ebenfalls über das \ac{JSON}-Format. Genaueres hierzu folgt in Abschnitt \ref{sec:umsetzung-data}.

\subsection{webifier Plattform}

In diesem Abschnitt wird nun die Umsetzung von webifier Plattform berschrieben. Diese Komponente wurde mit Java umgesetzt und basiert auf dem Spring-Framework. Zusätzlich kamen im Frontend die Technologiern \ac{HTML}, \ac{CSS} und JavaScript, sowie die Bibliotheken Bootstrap und jQuery zu Einsatz. Zunächst wird nun das Backend beschrieben, danach wird die Oberfläche der Plattform vorgestellt.

webifier Plattform ist eine Webanwendung und bietet eine benutzerfreundliche Öberfläche zur Bedienung von webifier Tester. Um die Plattform für die optimale Nutzung des Testers zu konfigurieren gibt es die in Listing \ref{lst:platform-config} dargestellte Datei, mit der alle notwendigen Parameter angepasst werden können.

\begin{scriptsize}
\lstset{
    style=eclipsejavascript,
    caption={Konfigurationsdatei webifier Plattform},
    label={lst:platform-config}
}
\begin{lstlisting}
{
  "tester": {
    "command": "java -jar webifier-tester.jar -u #URL -i #ID -o JSON",
    "timeout": 15,
    "parallel": 1
  }
}
\end{lstlisting}
\end{scriptsize}

Zunächst muss in der Konfigurationsdatei der Befehl zur Ausführung des Testers angegeben werden. Standartmäßig sollte der Tester im selben Verzeichnis liegen wie die Plattform. Ist dies nicht der Fall, muss der Pfad der Datei entsprechend geändert werden. Außerdem kann ein Timeout für den Tester angegeben werden. Standardmäßig liegt dieses bei 15 Minuten. Der wahrscheinlich wichtigste Parameter zur optimale Nutzung der vorhandenen Ressourcen ist der letzte Parameter. Mit diesem kann angegeben werden wie viele Tests parallel ausgeführt werden sollen. Per default werden alle Tests sequentiell ausgeführt. Wird die Plattform auf einem leistungsstarken System betrieben kann die anzahl entsprechend der vorhandenen Ressourcen angepasst werden.

Die Plattform stellt außerdem eine Möglichkeit zur Massenüberprüfung von Webseiten zur Verfügung. Hierfür kann eine Liste von Urls in form eines Texts oder einer Datei angegeben werden. In diesem Modus ist es allerdings nicht möglich alle Ergebnisse dierekt zu sehen, da der Vorgang je nach größe der Liste mehrere Tage oder Wochen dauern kann. Deshalb ist dieser Modus eher für langfristige Analysen geeignet.

Im Folgenden wird nun noch einmal der Ablauf einer Überprüfung beschrieben und die Oberfläche von webifier Plattform dargestellt. Besucht der Nutzer die Webseite der PLattform sieht er zunächst die in Abbildung \ref{fig:platform-start} gezeigte Startseite. Hier kann der User nun eine beliebige Url in das Eingabefeld tippen und anschließend die Überprüfung starten. Außerdem bietet die Startseite Links zur bereits beschriebenen Batchverarbeitung und zu webifier Statistics. Dieses Modul wird in Abschnitt \ref{sec:umsetzung-statistics} ausführlich dargestellt wird.

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{images/platform/screenshot-start}
  \caption{webifier Platform - Startseite}
  \label{fig:platform-start}
\end{figure}

Nachdem die Überprüfung einer Webseite gestartet wurde wird der Nutzer auf die in Abbildung \ref{fig:platform-result} abgebildete Seite geleitet, welche sich nach und nach mit den Ergebnissen der einzelnen Tests füllt, sobald diese vorliegen. Sind alle Tests beendet, wird auch das Endresultat angezeigt. Die Ergebnisseite bietet zunächst einen kompakten Überblick über alle ausgeführten Tests und deren Ergebnisse.

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{images/platform/screenshot-reflexonature}
  \caption{webifier Platform - Ergebnisseite}
  \label{fig:platform-result}
\end{figure}

Möchte der Nutzer noch genauere Informationen zu den Ergebnissen eines Tests, so lassen sich alle Testfelder mit einem Klick darauf ausklappen. Im Folgenden werden nun die Detailansichten der einzelnen Testergebnisse gezeigt und erläutert.

\begin{figure}[H]
  \centering
  \includegraphics[width=7.5cm]{images/platform/virusscan-malicious}
  \caption{webifier Platform - Virenscan der Webseite}
  \label{fig:platform-result-virusscan}
\end{figure}

Die Detailansicht des Virenscans, welche in Abbildung \ref{fig:platform-result-virusscan} dargestellt ist, zeigt einmal die Anzahl aller gescannten Dateien, sowie die Anzahlen der gefundenen verdächtigen oder maliziösen Dateien. Außerdem erhält die Ansicht eine genaue Auflistung aller Dateien mit entsprechendem Ergebnis. So lässt sich genau feststellen, welche Dateien welche Bedrohung darstellen.

\begin{figure}[H]
\centerline{%
\includegraphics[width=0.5\textwidth]{images/platform/header-inspection-clean}%
\includegraphics[width=0.5\textwidth]{images/platform/header-inspection-suspicious}%
}%
\caption{webifier Platform - Vergleich in verschiedenen Browsern}
\label{fig:platform-result-header-inspection}
\end{figure}

Der Vergleich in verschiedenen Browsern zeigt die maximale und die durchschnittliche Abweichung, sowohl als absoluten, als auch als prozentualen Wert. Zusätzlich erhält der Nutzer eine Übersicht uber alle Systeme, welche getestet und miteinander verglichen wurden. Zwei Beispielergebnisse hierfür sind in Abbildung \ref{fig:platform-result-header-inspection} zu sehen.

\begin{figure}[H]
\centerline{%
\includegraphics[width=0.5\textwidth]{images/platform/portscan-clean}%
\includegraphics[width=0.5\textwidth]{images/platform/portscan-malicious}%
}%
\caption{webifier Platform - Überprüfung der Port-Nutzung}
\label{fig:platform-result-portscan}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=7.5cm]{images/platform/ipscan-clean}
  \caption{webifier Platform - Überprüfung der IP-Nutzung}
  \label{fig:platform-result-ipscan}
\end{figure}

Abbildung \ref{fig:platform-result-portscan} zeigt die Ergebnisse der Überprüfung der Port-Nutzung, welche im Falle eines verdächtigen oder bedrohlichen Ergebnisses eine Liste mit allen gefundenen Ports enthält. Das Ergebnis der Überprüfung der IP-Nutzung ist gleich aufgebaut und in Abbildung \ref{fig:platform-result-ipscan} abgebildet. Es stellt bei entsprechenden Funden eine Liste aller IP-Adressen bereit.

\begin{figure}[H]
  \centering
  \includegraphics[width=7.5cm]{images/platform/linkchecker-undefined}
  \caption{webifier Platform - Prüfung aller verlinkten Seiten}
  \label{fig:platform-result-linkchecker}
\end{figure}

Das Ergebnis der Prüfung aller verlinkten Seiten enthält eine einfache Liste mit allen gefundenen Links und dem entsprechenden Ergebnis aus webifier Data. Abbildung \ref{fig:platform-result-linkchecker} zeigt eine solche Liste.

\begin{figure}[H]
\centerline{%
\includegraphics[width=0.5\textwidth]{images/platform/google-safe-browsing-clean}%
\includegraphics[width=0.5\textwidth]{images/platform/google-safe-browsing-malicious}%
}%
\caption{webifier Platform - Google Safe Browsing}
\label{fig:platform-result-google-safe-browsing}
\end{figure}

Die Deteilansicht des Google Safe Browsing Ergebnisses ist ähnlich dem der Prüfung aller verlinkten Seiten. Allerdings listet diese nur alle gefundenen Bedrohungen auf und nicht alle geprüften Links. Abbildung \ref{fig:platform-result-google-safe-browsing} enthält zwei Beispielresultate.

\begin{figure}[H]
\centerline{%
\includegraphics[width=0.5\textwidth]{images/platform/certificatechecker-clean}%
\includegraphics[width=0.5\textwidth]{images/platform/certificatechecker-malicious}%
}%
\caption{webifier Platform - Überprüfung des SSL-Zertifikats}
\label{fig:platform-result-certificatechecker}
\end{figure}

Das Ergebnis der Überprüfung des SSL-Zertifikates enthält alle Informationen des Zertifikats, sofern die Webseite eines nutzt. Wie in Abbildung \ref{fig:platform-result-certificatechecker} dargestellt, zeigt die Detailansicht einmal für wen das Zertifikat ausgestellt wurde, aber auch wer es ausgestellt hat. Außerdem wird der Gültigkeitszeitraum des Zertifikats angezeigt und im Fehlerfall der gefundene Fehler.

\begin{figure}[H]
\centerline{%
\includegraphics[width=0.5\textwidth]{images/platform/phishing-clean}%
\includegraphics[width=0.5\textwidth]{images/platform/phishing-malicious}%
}%
\caption{webifier Platform - Erkennung von Phishing}
\label{fig:platform-result-phishingdetector}
\end{figure}

Die Erkennung von Phishing stellt ebenfalls einige Informationen zur Verfügung, wie Abbildung \ref{fig:platform-result-phishingdetector} zeigt. Es werden in jedem Fall die gefundenen Schlagwörter der Webseite angezeigt. Ist das Ergebnis verdächtig oder bedrohlich, so wird die vermeindliche Originalseite verlinkt, die Werte der prozentualen Übereinstimmungen insgesamt und von Inhalt, Quelltext und Aussehen separat aufgelistst und ein Bild der beiden überlagerten Seiten gezeigt. Alle Inhalte, welche sich unterscheiden werden rosa dargestellt. Im Beispiel aus der Abbildung unterscheidet sich demnach nur der Text der Fußzeile.

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{images/platform/screenshot-clean}
  \caption{webifier Platform - Screenshot der Seite}
  \label{fig:platform-result-screenshot}
\end{figure}

Der Screnenshot der Seite wird beim ausklappen des Panels einfach angezeigt, so wie es in Abbildung \ref{fig:platform-result-screenshot} dargestellt. Dies gibt dem Nutzer die Möglichkeit sich die Webseite anzusehen, ohne sie selbst zu besuchen.

Wie nun gezeigt bietet die Plattform seh viele interessante Zusatzinformationen zu den Testergebnissen, mit denen das Gesamtresultat noch genauer erklärt wird. Außerdem bekommt der Nutzer so genügend Informationen um die Plausibilität der Testergebnisse selbst noch einmal zu überprüfen.

\subsection{webifier Mail}

\todo{Daniel}

\subsection{webifier Data}
\label{sec:umsetzung-data}

webifier Data stellt eine Schnittstelle zur globalen Datenspeicherung der Testresultate zur Verfügung. Die Komponente setzt ebenfalls auf dem Spring-Framework auf und wurde deshalb in Java implementiert. Außerdem wird die Spring-Bibliothek Spring-Data eingesetzt um Java-Objekte auf Dokumente zu übertragen und in einer MongoDB zu persistieren.

Das Modul bietet eine \ac{REST}-\ac{API} zur externen Nutzung, beispielsweise im webifier Tester oder in der Prüfung aller verlinkten Seiten. Die API stellt die folgenden Aktionen bereit: \lstinline[style=eclipse]{/push}, \lstinline[style=eclipse]{/check} und \lstinline[style=eclipse]{/count}. Mit der Methode \lstinline[style=eclipse]{/push} können Testergebnisse in webifier Data abgelegt werden. Die entsprechende Resource, welche im Inhalt des POST-Requests gesendet werden muss ist in Listing \ref{lst:data-push} dargestellt.

\begin{scriptsize}
\lstset{
    style=eclipsejavascript,
    caption={Ausschnitt Inhalt push-Request - webifier Data},
    label={lst:data-push}
}
\begin{lstlisting}
{
    "id" : "33e76954-dc94-48a9-a816-99ddeb647887",
    "enteredUrl" : "securitysquad.de",
    "testedUrl" : "https://www.securitysquad.de/",
    "result" : {
        "resultType" : "CLEAN",
        "resultValue" : 0
    }
    "duration" : 46220,
    "testResults" : [
        {
            "testId" : "33e76954-dc94-48a9-a816-99ddeb647887_07bb1b72-fd9f-4286-ade5-2d71cf47580a",
            "testData" : {
                "name" : "VirusScan",
                "startup" : "docker run --rm --name #ID -e URL=#URL -e ID=#ID webifier-test-virusscan",
                "shutdown" : "docker stop #ID",
                "enabled" : true,
                "weight" : 5,
                "startupTimeoutInSeconds" : 600,
                "shutdownTimeoutInSeconds" : 30,
            },
            "result" : {
                "result" : "CLEAN",
                "resultInfo" : {
                    ...
                }
            },
            "duration" : 31191
        },
        ...
    ]
}
\end{lstlisting}
\end{scriptsize}

Die Methode \lstinline[style=eclipse]{/check} bietet die Möglichkeit webifier Data nach einer oder mehreren Urls zu durchsuchen. Hierfür muss im Inhalt des POST-Requests die in Listing \ref{lst:data-check-request} gezeigte Ressource gesendet werden. Diese enthält eine Liste der zu überprüfenden Links.

\begin{scriptsize}
\lstset{
    style=eclipsejavascript,
    caption={Inhalt check-Request - webifier Data},
    label={lst:data-check-request}
}
\begin{lstlisting}
{
    "urls": [
        "https://fonts.googleapis.com/css?family=Montserrat:400,700",
        "https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic",
        "https://www.google.com/recaptcha/api.js",
        "https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js",
        "https://www.gstatic.com/recaptcha/api2/r20170503135251/recaptcha__de.js",
        "https://fonts.gstatic.com/s/lato/v13/v0SdcGFAl2aezM9Vq_aFTQ.ttf",
        "https://fonts.gstatic.com/s/lato/v13/DvlFBScY1r-FMtZSYIYoYw.ttf",
        "https://www.gstatic.com/recaptcha/api2/r20170503135251/fallback__ltr.css",
        "https://fonts.googleapis.com/css?family=Roboto:400,500",
        "https://www.gstatic.com/recaptcha/api2/logo_48.png",
        "https://github.com/SecuritySquad",
        "https://www.webifier.de/",
        "https://github.com/SecuritySquad/webifier-platform",
        "http://djbrown.de/",
        "https://www.facebook.com/danjoebro",
        "https://github.com/djbrown",
        "https://plus.google.com/114056971447496286521",
        "https://github.com/jockelmore",
        "https://samuel-philipp.de/",
        "https://github.com/samuel-p",
        "https://plus.google.com/u/0/+SamuelPd"
    ]
}
\end{lstlisting}
\end{scriptsize}

Wie Listing \ref{lst:data-check} zeigt gruppiert webifier Data zunächst alle Links anhand deren Host-Teil und entfernt alle ungültigen Einträge. Anschließend werden alle Resultate für jeden Eintrag der Liste geladen und daraus ein Gesamtergebnis pro Host berechnet. Dieses wird schließlich mit dem Host als schlüssel zur Liste \textit{hostResults} hinzugefügt. Abschließend wird die erzeugte Liste als Ergebnis zurückgegeben und als Antwort zurückgesendet. Diese Antwort ist in Listing \ref{lst:data-check-response} abgebildet.

\begin{scriptsize}
\lstset{
    style=eclipsejava,
    caption={Verarbeitung check Methode - webifier Data},
    label={lst:data-check}
}
\begin{lstlisting}
$$@Override$$
public WebifierCheckTestResultsResponse checkTestResultsRequest(WebifierCheckTestResultsRequest request) {
    List<String> hosts = request.getUrls().stream().map(url -> {
        try {
            return filterHost(url);
        } catch (MalformedURLException e) {
            return null;
        }
    }).distinct().filter(StringUtils::isNotEmpty).collect(toList());
    Map<String, WebifierTestResultDetails> hostResults = new HashMap<>();
    hosts.forEach(host -> {
        List<WebifierTestResultData> data = #dataPersistenceService#.getTestResultDataByHost(host)
                .stream().filter(d -> d.getOverallResultType() != WebifierTestResult.##UNDEFINED##).collect(toList());
        if (data.isEmpty()) {
            hostResults.put(host, WebifierTestResultDetails.##UNDEFINED##);
        } else {
            double resultValue = data.stream().mapToDouble(this::mapDataResultToIndex).average().orElse(1);
            hostResults.put(host, mapResultValueToResult(resultValue));
        }
    });
    if (hostResults.isEmpty()) {
        return new WebifierCheckTestResultsResponse(false);
    }
    return new WebifierCheckTestResultsResponse(true, hostResults);
}
\end{lstlisting}
\end{scriptsize}

\begin{scriptsize}
\lstset{
    style=eclipsejavascript,
    caption={Inhalt check-Response - webifier Data},
    label={lst:data-check-response}
}
\begin{lstlisting}
{
    "success": true,
    "hosts": {
        "www.facebook.com": "CLEAN",
        "fonts.googleapis.com": "UNDEFINED",
        "plus.google.com": "CLEAN",
        "fonts.gstatic.com": "UNDEFINED",
        "cdnjs.cloudflare.com": "UNDEFINED",
        "github.com": "CLEAN",
        "djbrown.de": "UNDEFINED",
        "samuel-philipp.de": "UNDEFINED",
        "www.google.com": "SUSPICIOUS",
        "www.gstatic.com": "UNDEFINED",
        "www.webifier.de": "CLEAN"
    }
}
\end{lstlisting}
\end{scriptsize}

Die Methode \lstinline[style=eclipse]{/count} liefert einfach die aktuelle Gesamtzahl der in webifier Data vorhandenen Testergebnisse.

Die Testergebnisse werden in der MongoDB auf zwei Dokumente verteilt. Das erste Dokument (\lstinline[style=eclipse]{webifierTestResultData}) enthält alle Gesamtdaten des Resultats, das zweite (\lstinline[style=eclipse]{webifierSingleTestResultData}) umfasst alle Einzelergebnisse des Resultats. Deshalb werden pro Testergebnis ein Dokument in \lstinline[style=eclipse]{webifierTestResultData} und acht in \lstinline[style=eclipse]{webifierSingleTestResultData} gespeichert.

Zur Persistierung werden alle Informationen der \lstinline[style=eclipse]{\push} Methode (Listing \ref{lst:data-push}) auf die entspechenden Dokumente gemappt. Listing \ref{lst:data-resultdata} zeigt die transformierten Daten aus \lstinline[style=eclipse]{webifierTestResultData}. Anhang \appref{d} enthält die transformierten Dokumente aller Einzelergebnisse in \lstinline[style=eclipse]{webifierSingleTestResultData}.

\begin{scriptsize}
\lstset{
    style=eclipsejavascript,
    caption={Beispieldokument webifierTestResultData - webifier Data},
    label={lst:data-resultdata}
}
\begin{lstlisting}
{
	"_id" : "d62e8c94-21c9-4d69-9337-186b38f73cce",
	"_class" : "de.securitysquad.webifier.persistence.domain.WebifierTestResultData",
	"testerId" : "56821bd8-f652-4b59-b7ec-12faa7cf6cae",
	"enteredUrl" : "ukauctionline.co.uk",
	"testedUrl" : "http://ukauctionline.co.uk",
	"host" : "ukauctionline.co.uk",
	"overallResultType" : "SUSPICIOUS",
	"overallResultValue" : 0.057291666666666664,
	"durationInMillis" : NumberLong(227639),
	"datetime" : ISODate("2017-03-28T22:32:53.834Z"),
	"testResults" : [
		DBRef("webifierSingleTestResultData", "5ecb25e6-457b-41ab-9241-a60f8a484131"),
		DBRef("webifierSingleTestResultData", "abb70569-64d3-47ae-b3e3-ff8086c8f937"),
		DBRef("webifierSingleTestResultData", "56dbbcb3-9628-4dd4-bb20-692bd86c5410"),
		DBRef("webifierSingleTestResultData", "64ae09d4-a79e-4194-b77c-3a7891342567"),
		DBRef("webifierSingleTestResultData", "05ba8488-4b69-40f9-8a9d-661c09daab65"),
		DBRef("webifierSingleTestResultData", "e0ce8955-feb7-4f7a-adfb-b7b8116a9d28"),
		DBRef("webifierSingleTestResultData", "9affd5e9-37eb-4d83-b471-ceab0c19155c"),
		DBRef("webifierSingleTestResultData", "c2b02bf9-2073-451b-a566-295fe1801e51")
	]
}
\end{lstlisting}
\end{scriptsize}

\subsection{webifier Statistics}
\label{sec:umsetzung-statistics}

Webifier Statistics wird in R implementiert. Hierzu werden Flexdashboards\footnote{Siehe http://rmarkdown.rstudio.com/flexdashboard/index.html} verwendet. Zur Generierung der Grafiken wurde auf verschiedene Librarys, wie beispielsweise Plot.ly, zurückgegriffen um den Entwicklungsaufwand für die Visualisierungen zu minimieren. Die Anordnung der Grafiken wird über ein bestimmtes Layout definiert. Jede Grafik wird prinzipiell in 3 Schritten erstellt:

\begin{enumerate}
  \item Daten aus der MongoDB laden
  \item Daten in die benötigte Form transformieren
  \item Entsprechende API ansteuern für Generierung der Grafik
\end{enumerate}

\begin{scriptsize}
\lstset{
    style=eclipsejavascript,
    caption={Beispiel R-Grafik},
    label={lst:rgrafik}
}
\begin{lstlisting}
  ### Durchschnittliche Analysezeit

  ```{r}
  result <- dbGetQueryForKeys(mg1, 'webifierTestResultData',"{}", "{durationInMillis:1}",skip=0,limit=Inf)
  mean.dur <- mean(result$durationInMillis)/1000
  mean.dur <- round(mean.dur)
  tp <- seconds_to_period(mean.dur)
  valueBox(paste(minute(tp),'min ',second(tp),'s',sep=""), icon="fa-hourglass-half",color="grey")
  ```
\end{lstlisting}
\end{scriptsize}

Im Codebeispiel \ref{lst:rgrafik} ist der Codeablauf für eine Valuebox zu sehen. Dieses Beispiel wurde ausgewählt um den Erstellungsprozess für die Grafiken zu erklären. Dies lässt sich auf alle anderen Grafiken übertragen.

Die Überschriften der Grafiken werden mit \textit{\#\#\#} markiert. Der R-Code befindet sich in Chunks, diese werden speziell markiert um dem Compiler kenntlich zu machen welches der R-Code ist.

Im Beispiel werden zunächst benötigten Daten aus der MongoDB geladen. Da hier eine Valuebox für die Anzeige der durchschnittlichen Analysezeit generiert wird werden nur die Analysezeiten(durationInMillis) benötigt. Diese werden anschließend gemittelt und von Millisekunden in Minuten/Sekunden transformiert. Zur Erstellung der Valuebox muss nun nurnoch der Text, die Farbe und ein passendes Icon ausgewählt werden. Die Generierung und Platzierung übernimmt Flexdashboard. Als Ausgabe wird eine HTML-Datei generiert, welche dann in den Webserver eingebunden wird um sie für die Nutzer zugänglich zu machen.

\begin{figure}[H]
  \centering
  \includegraphics[width=5cm]{images/stats/valuebox}
  \caption{Generierte Valuebox}
  \label{fig:valuebox}
\end{figure}

In Abbildung \ref{fig:valuebox} ist die fertig generierte Valuebox mit Überschrift, Text und Icon in passender Farbe dargestellt.

Für stets aktuelle Grafiken wird das R-Skript für die Statistiken mehrfach täglich neu gebaut um die aktuellen Daten mit einzubeziehen. Von einer \textit{On the fly}-Generierung der Grafiken wurde abgesehen, da dies für den Server zu rechenintensiv wäre.

\section{Tests}

\subsection{Virenscan der Webseite}

\todo{Samuel}

\begin{itemize}
  \item Httrack (Umsetzung)
  \item Download aller Dateien der Webseite
  \item Scannen der Heruntergeladenen Dateien
  \begin{itemize}
    \item Clamav (Umsetzung)
    \item AVG (Umsetzung)
    \item CAV (Umsetzung)
  \end{itemize}
\end{itemize}

\subsection{Vergleich in verschiedenen Browsern}

\todo{Daniel}

\subsection{Überprüfung der Port-Nutzung}
Bei diesem Test wird überprüft ob die Seite versucht einen Portscan auf dem Computer des Anwenders zu betreiben. Hierfür werden 3 Techniken eingesetzt. Die wichtigsten Aufgaben werden von PhantomJS und Bro erledigt.
Bro ist ein Netzwerkmonitoringtool und wird hier genutzt um den Traffic welcher zwischen Webseite und Client entsteht zu protokollieren und in einer Logdatei abzuspeichern. PhantomJS ist ein \textit{headless Browser}, welcher genutzt wird um die Webseite aufzurufen und dessen Javascript auszuführen. Das ganze funktioniert hier ohne grafische Oberfläche.

Der Ablauf des Tests sieht wie folgt aus: Zunächst wird Bro intialisiert und es werden Filter angelegt um lediglich die Ports, der eingehenden Anfragen, mitzuloggen und in der Logdatei abzuspeichern. Ist Bro vollständig initialisiert und einsatzbereit startet PhantomJS mit dem Aufrufen der Seite und Ausführen des JavaScript-Codes. Währenddessen speichert Bro alle Netzwerkaktivitäten. Sobald der Durchlauf von PhantomJS abgeschlossen ist wird mittels Python die Validierung des Ergebnisses gestartet. Hier werden die angefragten Ports aus der Logdatei geladen und klassifiziert. Die Ports 80 und 443 werden verworfen, da diese die HTTP und SSL Ports sind und somit als harmlos klassifiziert werden können. Die weiteren Ports werden in einer Liste an riskanten Ports gespeichert. Die Anzahl an Ports in dieser Liste bestimmt nun das Ergebnis des Testes. Wurden keine verdächtigen Portanfragen gefunden wird das Ergebnis \textit{unbedenklich} übermittelt. Bei 1 oder 2 Ports in der Liste gibt der Test \textit{verdächtig} als Ergebnis zurück. Sollte die Anzahl größer gleich 3 sein wird die Seite von diesem Test als \textit{bedrohlich} eingestuft. Zusätzlich zum Ergebnis wird die Liste der riskanten Ports in der Ergebnisinformation weitergeleitet.

\subsection{Überprüfung der IP-Nutzung}
Der Test auf verdächtige IP-Anfragen ist bis auf 2 Änderungen identisch zu vorherigem Test auf Portscanning. Deshalb werden in diesem Kapitel nur die Unterschiede beleuchtet.

Der erste Unterschied liegt in der Initialisierung von Bro. Hier werden Filter angewendet um die IPs, der ausgehenden Anfragen, zu loggen. Hier müssen die ausgehenden Anfragen betrachtet werden, da bei dieser Art von Angriff versucht wird mittels clientseitig ausgeführtem JavaScript das Netzwerk des Anwenders auszuspähen. Den Aufruf der Seite übernimmt auch hier PhantomJS. Bei der darauf folgenden Validierung werden die IPs auf bekannte Heimnetzadressbereiche wie beispielsweise 192.168.178.* oder 192.168.2.* gemappt. Auch hier werden verdächtige IPs in einer Liste gespeichert. Die Anzahl der Elemente in dieser Liste bestimmt das Ergebnis des Testes. Hierbei sind die Schwellwerte identisch mit denen des Portscanning-Tests, also bei 0 Abfragen wird \textit{sauber} zurückgegeben, bei 1-2 wird \textit{verdächtig} zurückgegeben und bei >3 wird die Seite als \textit{bedrohlich} eingestuft. Zusätzlich zum Ergebnis wird die Liste der riskanten IPs in der Ergebnisinformation weitergeleitet.

\subsection{Prüfung aller verlinkten Seiten}

\todo{Daniel}

\subsection{Google Safe Browsing}

\todo{Daniel}

\subsection{Überprüfung des SSL-Zertifikats}

\todo{Samuel}

\begin{itemize}
  \item Auslesen der relevanten Informationen des Zertifikates der Webseite
  \item Validierung des Zertifikates
\end{itemize}

\subsection{Erkennung von Phishing}
\label{sec:umsetzung-phishungdetector}

\todo{Samuel}

\begin{itemize}
  \item Herausfiltern der Schlagwörter
  \item Finden möglicher Duplikate der Webseite
  \begin{itemize}
    \item Erstes Schlagwort zu Top Level Domains
    \begin{itemize}
      \item com
      \item ru
      \item net
      \item org
      \item de
    \end{itemize}
    \item Websuche nach den Schlagwörtern mittels Suchmaschinen
    \begin{itemize}
      \item DuckDuckGo
      \item Ixquick
      \item Bing
    \end{itemize}
  \end{itemize}
  \item Berechnung Teilergebnisse
\end{itemize}

\subsection{Screenshot der Seite}
Der Screenshot der Seite erfolgt über eine von PhantomJS gelieferte Methode um den Seiteninhalt aufzunehmen und als Bilddatei abzuspeichern. PhantomJS wird hierbei genutzt da der Test in einem Docker ohne grafische Benutzeroberfläche läuft und deshalb ein headless Browser nötig ist um die Seite aufzurufen. Nachdem die Seite in einer Bilddatei abgespeichert ist, wird diese als base64-encoded String weitergegeben. Der Test liefert immer das Ergebnis \textit{sauber}, welches aber für den Tester irrelevant ist, da der Screenshot-Test keine Gewichtung im Tester hat. In der Ergebnisinformation wird der base64 encodierte String weitergegeben, welcher dann von der Plattform interpretiert und als Bild für den Nutzer dargestellt wird.
